{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from numpy.testing import assert_array_almost_equal, assert_equal, assert_almost_equal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первое обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простое как пробка задание. Обучите классификатор [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) на входных данных с гиперпараметрами:\n",
    "\n",
    "* `max_depth`=$6$\n",
    "* `min_samples_split`=$3$\n",
    "* `min_samples_leaf`=$3$\n",
    "* `n_estimators`=$100$\n",
    "* `n_jobs`=$-1$\n",
    "\n",
    "И верните обученную модель.\n",
    "\n",
    "Данные в X только численные, в y только 2 значения: 0 и 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def fit_rf(X: np.ndarray, y:np.ndarray) ->  RandomForestClassifier:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "np.random.seed(1337)\n",
    "n = 200\n",
    "a = np.random.normal(loc=0, scale=1, size=(n, 2)) # первый класс\n",
    "b = np.random.normal(loc=3, scale=2, size=(n, 2)) # второй класс\n",
    "X_clf = np.vstack([a, b]) # двумерный количественный признак\n",
    "y_clf = np.hstack([np.zeros(n), np.ones(n)]) # бинарный признак\n",
    "\n",
    "model = fit_rf(X_clf, y_clf)\n",
    "assert model.n_estimators == 100\n",
    "assert model.max_depth == 6\n",
    "assert model.min_samples_split == 3\n",
    "assert model.min_samples_leaf == 3\n",
    "\n",
    "assert_equal(model.predict(np.array([[0, 0]])), np.array([0.]))\n",
    "assert_equal(model.predict(np.array([[3, 3]])), np.array([1.]))\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первая классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В [папке data](https://github.com/samstikhin/ml2021/tree/master/02-IntroML) вы можете найти данные для бинарной классификации (`diabets_train.csv`, `diabets_test.csv` и `diabetes_answers.csv`). $Y$ в этих данных выступает столбик `Outcome`, в качестве $X$ - все остальное. \n",
    "\n",
    "Вам необходимо предсказать $y_{test}$ такой, что $accuracy > 0.75$ ([доля правильных ответов](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)). Вы можете делать что угодно, чтобы получить результат:\n",
    "\n",
    "* использовать любой классификатор с любыми гиперпараметрами\n",
    "* как угодно изменять данные \n",
    "\n",
    "Вернуть в этом случае нужно не модель, а результат - одномерный массив данных $y_{pred}$ (предсказание $y_{test}$).\n",
    "\n",
    "P.S. Можете узнать больше о данных по [ссылке](https://www.kaggle.com/uciml/pima-indians-diabetes-database). Мы произвольным образом разбили данные в соотношении 4:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classification(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray) -> np.ndarray:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "df_train = pd.read_csv('diabetes_train.csv')\n",
    "df_test = pd.read_csv('diabetes_test.csv')\n",
    "\n",
    "X_train = df_train.drop(columns=['Outcome']).values\n",
    "y_train = df_train['Outcome']\n",
    "\n",
    "X_test = df_test.values\n",
    "y_test = pd.read_csv('diabetes_answers.csv')['Outcome']\n",
    "\n",
    "y_pred = classification(X_train, y_train, X_test)\n",
    "assert sklearn.metrics.accuracy_score(y_test, y_pred) > 0.74\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В [папке data](https://github.com/samstikhin/ml2021/tree/master/02-IntroML) вы можете найти данные для бинарной классификации (файлы `overfit_trian.csv`, `overfit_test.csv`). Вам на вход подается тренировочная и тестовая выборки из файла. \n",
    "\n",
    "Верните такую обученную модель, которая на тренировочной выборке дает $accuracy > 0.97$, а на тестовом $accuracy < 0.7$.\n",
    "\n",
    "[$accuracy$](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) - доля правильных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def overfitting(X_train: np.array, y_train: np.array, X_test: np.array, y_test: np.array):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "df_train = pd.read_csv('overfit_train.csv')\n",
    "df_test = pd.read_csv('overfit_test.csv')\n",
    "\n",
    "X_train = df_train.drop(columns=['y']).values\n",
    "y_train = df_train['y']\n",
    "\n",
    "X_test = df_test.drop(columns=['y']).values\n",
    "y_test = df_test['y']\n",
    "\n",
    "model = overfitting(X_train, y_train, X_test, y_test)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred =  model.predict(X_test)\n",
    "assert sklearn.metrics.accuracy_score(y_train, y_train_pred) > 0.97\n",
    "assert sklearn.metrics.accuracy_score(y_test, y_test_pred) < 0.7\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мой KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваша задача реализовать свой простой KNNClassifier для бинарных данных. Вам нужно реализовать 3 метода:\n",
    "\n",
    "* `init` - начальная инициализация\n",
    "* `fit` - обучение классификатора\n",
    "* `predict` - предсказание для новых объектов\n",
    "* `predict_proba` - предсказание вероятностей новых объектов\n",
    "\n",
    "У нашего классификатора будет лишь один гиперпараметр - количество соседей $k$. Во избежании тонкостей: $k$ - нечетное.\n",
    "\n",
    "На вход будет подаваться выборка объектов $X$, у которых ровно 2 числовых признака. $y$ - результат бинарной классификации $0$ или $1$.\n",
    "\n",
    "Метрика ближайших элементов - Эвклидова.\n",
    "\n",
    "Напоминание: $y$ - одномерный массив, $X$ - двумерный массив, по $0$-ой оси которой расположены объекты.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "X_train = np.array([[1, 1], [1, -1], [-1,-1], [-1, 1]])\n",
    "y_train = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = KNN(k=3).fit(X_train, y_train)\n",
    "y_pred = model.predict(np.array([[0.5, 0.5], [ -0.5,  -0.5]]))\n",
    "y_prob = model.predict_proba(np.array([[0.5, 0.5], [-0.5, -0.5]]))\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "y_pred = np.array([1., 0.])\n",
    "y_prob = np.array([[0.33, 0.667],\n",
    "                   [0.667, 0.33]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, k=3):\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train:np.array): #обучаем классификатор\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test: np.array): #предсказываем значения\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, X_test: np.array): #предсказываем вероятности\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "######################################################\n",
    "X_clf = np.array([[1, 1], [1, -1], [-1,-1], [-1, 1]])\n",
    "y_clf = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = KNN(k=3).fit(X_clf, y_clf)\n",
    "\n",
    "assert_equal(model.predict(np.array([[-0.5, -0.5]])), np.array([0.]))\n",
    "assert_equal(model.predict(np.array([[ 0.5,  0.5]])), np.array([1.]))\n",
    "assert_almost_equal(model.predict_proba(np.array([[0.5, 0.5], [-0.5, -0.5]])), \n",
    "                    np.array([[0.33, 0.667],\n",
    "                              [0.667, 0.33]]), \n",
    "                    decimal=2)\n",
    "######################################################\n",
    "np.random.seed(1337)\n",
    "n = 200\n",
    "a = np.random.normal(loc=0, scale=1, size=(n, 2)) # первый класс\n",
    "b = np.random.normal(loc=3, scale=2, size=(n, 2)) # второй класс\n",
    "X = np.vstack([a, b]) # двумерный количественный признак\n",
    "y = np.hstack([np.zeros(n), np.ones(n)]) # бинарный признак\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=1645)\n",
    "\n",
    "model = KNN(k=3).fit(X_train, y_train)\n",
    "model_real = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "\n",
    "assert_array_almost_equal(model.predict(X_test), model_real.predict(X_test))\n",
    "assert_array_almost_equal(model.predict_proba(X_test), model_real.predict_proba(X_test))\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Моя Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вам предстоит реализовать свою простейшую линейную регрессию по функционалу $MSE$.\n",
    "\n",
    "Линейная регрессия выглядит следующим образом:\n",
    "$$a(x) = w_1x + w_0$$\n",
    "\n",
    "Необходимо найти такие $w_0$ и $w_1$, при которых минимизируется значение\n",
    "\n",
    "$$MSE(X,Y) = \\frac{1}{n}\\sum_{i=1}^{n}(a(x_i) - y_i)^2$$\n",
    "\n",
    "Выведите формулы для $w_0$ и $w_1$ аналитически и реализуйте следующие методы класса \n",
    "\n",
    "* `init` - начальная инициализация\n",
    "* `fit` - обучение классификатора\n",
    "* `predict` - предсказание для новых объектов\n",
    "\n",
    "После обучения у модели должен присутствовать атрибут `model.coef_` из которого можно получить коэффициенты регрессии в порядке: $w_1$, $w_0$.\n",
    "\n",
    "Гиперпараметры отсутствуют.\n",
    "\n",
    "На вход будут подаваться два массива $X\\in \\mathbb{R}^{n}$ и $Y \\in \\mathbb{R}^{n}$.\n",
    "\n",
    "Метрика - Евклидова.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "X_train = np.array([[1], [2]])\n",
    "y_train = np.array([1, 2])\n",
    "\n",
    "model = LinReg().fit(X_train, y_train)\n",
    "y_pred = model.predict(np.array([[3],[4]]))\n",
    "\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "y_pred = np.array([3, 4])\n",
    "model.coef_ = np.array([1., 0.])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg():\n",
    "    def __init__(self):\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train:np.array): #обучаем регрессию\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test: np.array): #предсказываем значения\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "X_reg = np.array([[1], [2]])\n",
    "y_reg = np.array([1, 2])\n",
    "\n",
    "model = LinReg().fit(X_reg, y_reg)\n",
    "assert_array_almost_equal(model.predict(np.array([[3],[4]])), np.array([3, 4]), decimal=2)\n",
    "\n",
    "assert_array_almost_equal(model.predict(np.array([[0]])), np.array([0]), decimal=2)\n",
    "\n",
    "assert_array_almost_equal(model.coef_, np.array([1., 0.]), decimal=2)\n",
    "######################################################\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_reg, y_reg = make_regression(n_samples=200, n_features=1, n_targets=1)\n",
    "\n",
    "model = LinearRegression().fit(X_reg, y_reg)\n",
    "model2 = LinReg().fit(X_reg, y_reg)\n",
    "\n",
    "coef_real = np.array([model.coef_[0], model.predict(np.array([[0]]))[0]])\n",
    "coef_my = model2.coef_\n",
    "\n",
    "assert_array_almost_equal(coef_my, coef_real, decimal=3)\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный (зато свой) Байес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется написать свой классификатор, на основе наивного баеса. Необходимо реализовать аналог `MultinomialNB`. \n",
    "\n",
    "$$y_{test} = argmax_{c}\\ln{P(y_{test}=c)} + \\sum_{j=1}^{m}\\ln{(P(f_j|y_{test}=c) + \\alpha)}, ~~~ c\\in\\{0,1\\}$$\n",
    "\n",
    "На вход подаются численные категориальные признаки. Классы: $0$ и $1$. У классификатора будет единственный параметр - $alpha$.\n",
    "\n",
    "### Sample 1:\n",
    "#### Input:\n",
    "```python\n",
    "X_clf = np.array([[1, 1], [1, -1], [-1,-1], [-1, 1]])\n",
    "y_clf = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = MyNaiveBayes(alpha=1).fit(X_clf, y_clf)\n",
    "\n",
    "y_pred = model.predict(np.array([[1, 2], [-1, -2]]))\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "y_pred = [1, 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log\n",
    "\n",
    "class MyNaiveBayes():\n",
    "    def __init__(self, alpha=1):\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        assert X.ndim == 2\n",
    "        assert y.ndim == 1\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "            \n",
    "    def predict(self, X: np.ndarray):\n",
    "        assert X.ndim == 2\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "X_clf = np.array([[1, 1], [1, -1], [-1,-1], [-1, 1]])\n",
    "y_clf = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = MyNaiveBayes(alpha=1).fit(X_clf, y_clf)\n",
    "\n",
    "assert_equal(model.predict(np.array([[1, 2], [-1, -2]])), np.array([1, 0]))\n",
    "######################################################\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "random_state = 1448\n",
    "X, y = make_classification(n_samples=500, n_features=4, n_informative=2,\n",
    "                           scale=5, random_state=random_state)\n",
    "\n",
    "X = X.astype(np.int) \n",
    "X += np.abs(np.min(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=y)\n",
    "\n",
    "clf = MyNaiveBayes().fit(X_train, y_train)\n",
    "assert accuracy_score(y_test, clf.predict(X_test)) > 0.9\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Злобные твиты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наивный Байес очень хорошо подходит для Анализа тональности текста. То есть определить несет текст позитивный или негативный вайб :) \n",
    "\n",
    "В данной задаче вам даны [твиты про разные авиакомпании](https://github.com/samstikhin/ml2021/tree/master/02-IntroML) (файлы `tweets_train.csv`, `tweets_test.csv`). Требуется построить классификатор, который бы определял имеет ли твит положительную или негативную окраску. Напишите функцию `predict`, который возвращает массив, где 1 - это позитивный, 0 - негативный. \n",
    "\n",
    "В данной задаче вам понадобятся `TweetTokenizer` и `CountVectorizer`. \n",
    "\n",
    "* `TweetTokenizer` и любой tokenizer самостоятельно разбивает строку на слова как-то их модифицировав.\n",
    "* `CountVectorizer` превращает предложение в вектор чисел основываясь на их частоте, используя токенайзер.\n",
    "\n",
    "Задача делится на 2 пункта: \n",
    "\n",
    "* Preprocessing: переведите все слова в нижний регистр, токенизируйте слова с помощью `TweetTokenizer`, а дальше опять соберите в предложение. Проделайте это и в $X_{train}$ и $X_{test}$\n",
    "* Predict: переведите предложения в вектора количеств с помощь `CountVectorizer`. Обучите модель на данных и предскажите ответ.\n",
    "\n",
    "Чтобы получить баллы надо побить accuracy = 0.88\n",
    "\n",
    "\n",
    "P.S Можете посмотреть топ слов, которые с наибольшей вероятностью относятся к позитивным и негативным классам. \n",
    "\n",
    "P.P.S. Если ничего не понятно: можете изучить различные kernel на [kaggle](https://www.kaggle.com/crowdflower/twitter-airline-sentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer, TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def predict(df_train: pd.DataFrame, df_test: pd.DataFrame):\n",
    "    \n",
    "    # preprocess data here\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    model = MultinomialNB ...\n",
    "        \n",
    "    # fit model\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    return model.predict(...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train = pd.read_csv('tweets_train.csv')\n",
    "df_test = pd.read_csv('tweets_test.csv')\n",
    "\n",
    "y_test = ((df_test['airline_sentiment'] == 'positive').astype(np.int))\n",
    "X_test = df_test.drop(columns='airline_sentiment')\n",
    "\n",
    "assert accuracy_score(y_test, predict(df_train, df_test)) > 0.88\n",
    "######################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
